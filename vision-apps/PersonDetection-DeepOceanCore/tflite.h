// #DETECTION
#pragma once

// save diagnostic state
// from https://stackoverflow.com/questions/3378560/how-to-disable-gcc-warnings-for-a-few-lines-of-code
#pragma GCC diagnostic push
// turn off the specific warning. Can also use "-Wall"
#pragma GCC diagnostic ignored "-Wpedantic"
#pragma GCC diagnostic ignored "-Wunused-parameter"
#include "tensorflow/lite/interpreter.h"
#include "tensorflow/lite/kernels/register.h"
#include "tensorflow/lite/model.h"
#include "tensorflow/lite/optional_debug_tools.h"

// turn the warnings back on
#pragma GCC diagnostic pop

//#include <QVariantMap>
#include <vector>
#include <cnnmanager_v2.h>
#include <QRect>

/**
 * The Tflite class takes care of all layers CNN that can't be processed by the Deep Ocean Core. In this case we're using a Single Shot Detector for person detection.
 * The feature extraction runs on the Deep Ocean Core and includes the vast majority of operations.
 * Additionally, we need to include a thin box regression module and a box decoding module on top.
 * The latter two are generated as TfLite modules automatically by IDS NXT lighthouse or Ferry and included in the .det model included in this example Vision App.
 * The TfLite class takes the Deep Ocean Core output buffers and forwards processes them first by the box regression and then compiles the results in the box decoding
 */
class TfLite
{
public:
    /**
     * Struct containing the inference result for a single detection including a QList object names and confidence scores, a QRect for the box coordinates,
     * and a color value for the rendering of the box. The Struct is generated by the createResult method and can be forwarded to CustomResultImage::createOverlay
     * to overlay the boxes on top of the original image
     */
    struct overlayData {
        QList<QPair<QString, float>> inference;
        QRect cnnRoi;
        int color = 0;
    };

    /**
     * Struct containing the pointers to the CNN modules processed by TfLite
     */
    struct tfLiteFiles {
        std::shared_ptr<TfLite> box = nullptr;
        std::shared_ptr<TfLite> decoder = nullptr;
    };

    /**
     * Struct containing the output of the CNN model as processed by the doBoxDecoding method
     */
    struct boundingBoxes {
        std::vector<std::vector<float>> boxCoordinates;
        std::vector<int> classIndices;
        std::vector<float> classScores;
        int numberDetections = 0;
    };

    /**
     * @brief Constructor
     * @param ftlitemodel directory to a TfLite flatbuffer file
     *
     * The Constructor loads the TfLite flatbuffer file located at ftlitemodel, initializes the interpreter, and allocates the in- and output buffers
     */
    TfLite(const std::string &ftlitemodel);

    /**
     * @brief Process Deep Ocean Core Results
     * @param buffers Inference result as put out by the Deep Ocean Core
     * @return Encoded box proposal as genereated by TfLite box regression model
     */
    std::vector<std::vector<float>> doBoxRegression(const std::vector<IDS::NXT::CNNv2::ResultBuffer> &buffers);

    /**
     * @brief Process doBoxRegression results
     * @param boxProposals as generated by doBoxRegression
     * @param threshold confidence threshold for positive detections
     * @return boundingBoxes struct containing the decoded and filtered detection objects, scores, and coordinates
     */
    boundingBoxes doBoxDecoding(const std::vector<std::vector<float>> &boxProposals, float threshold);

    /**
     * @brief Puts a list of overlayData as generated by createResult in a json format ready for REST interface
     * @param input as generated by doBoxRegression
     * @return QJsonArray that can be added to a result collection
     */
    static QJsonArray createResultJson(const QList<overlayData> &input);
    /**
     * @brief Puts a QRect into a json format
     * @param QRect roi as used in overlayData
     * @return QJsonObject that can be added to a result collection
     */
    static QJsonObject roiToJson(const QRect &roi);

    /**
     * @brief Compiles a list of overlayData ready to be rendered by CustomResultImage::createOverlay
     * @param TfLite::boundingBoxes &detections as generated by the doBoxDecoding method
     * @param QSize &full describes the desired output image dimensions to scale the box coordinates
     * @param QSize &small absolute dimensions of the scaled image as processed by the CNN model
     * @param QStringList &classes list of class names to map the class indeces onto the corresponding names
     * @return QList<overlayData> ready to be used by CustomResultImage::createOverlay
     */
    static QList<overlayData> createResult(const TfLite::boundingBoxes &detections, const QSize &full, const QSize &small, const QStringList &classes);

private:
    std::unique_ptr<tflite::FlatBufferModel> _model = nullptr;
    std::unique_ptr<tflite::Interpreter> _interpreter = nullptr;
};

/**
 *This class combines all Steps for postprocessing the detection

 */
class BoundingBoxesProcessing
{
public:
    BoundingBoxesProcessing() = default;
    void setTFLiteFiles(const QPair<QString, QString> &currentTFLiteFiles);

    QList<TfLite::overlayData> processDetections(const std::unique_ptr<IDS::NXT::CNNv2::MultiBuffer> &buffer,
                                                 QSize fullSize,
                                                 QSize smallSize,
                                                 const QStringList &classes,
                                                 float threshold);

private:
    QPair<QString, QString> _tfLiteFiles;
    std::unique_ptr<TfLite> _box;
    std::unique_ptr<TfLite> _decoder;
};
